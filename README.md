# Little Timmy

Voice-enabled AI assistant with persistent vector memory, GPU-accelerated speech processing, and intelligent context retrieval.

## ğŸ¯ For New Agents/Developers - Start Here!

**To understand this project, read these documents in order:**

1. **ğŸ“– [SYSTEM_ARCHITECTURE.md](SYSTEM_ARCHITECTURE.md)** - Complete system overview, component diagram, and data flow
2. **ğŸ› ï¸ [DEVELOPMENT_GUIDE.md](DEVELOPMENT_GUIDE.md)** - Development workflow, Git operations, and environment setup
3. **ğŸ“‚ Component READMEs:**
   - [stt-server-v17/README.md](stt-server-v17/README.md) - Speech-to-Text server
   - [tts-server/README.md](tts-server/README.md) - Text-to-Speech server
   - [v34/README.md](v34/README.md) - LLM preprocessor with memory
   - [testing-interface/README.md](testing-interface/README.md) - Service control panel

**Repository Location:**
```
\\wsl.localhost\Ubuntu-20.04\home\gearscodeandfire\timmy-backend\little-timmy\
```

## ğŸš€ Quick Start

### **Launch All Services (Easiest)**

Double-click:
```
testing-interface\START_CONTROL_PANEL.bat
```

Then open http://localhost:5555 and start services.

### **Manual Launch**

See [DEVELOPMENT_GUIDE.md](DEVELOPMENT_GUIDE.md) for individual service startup commands.

## ğŸ“¦ Repository Structure

```
little-timmy/
â”œâ”€â”€ stt-server-v17/              # Speech-to-Text (faster-whisper + CUDA)
â”œâ”€â”€ tts-server/                  # Text-to-Speech (Piper + CUDA)
â”œâ”€â”€ v34/                         # LLM Preprocessor (GLiClass + Memory)
â”œâ”€â”€ testing-interface/           # Service Control Panel
â”œâ”€â”€ esp32_phoneme_to_jaw_openness/  # Hardware control (Arduino)
â”œâ”€â”€ SYSTEM_ARCHITECTURE.md       # ğŸ¯ START HERE for overview
â”œâ”€â”€ DEVELOPMENT_GUIDE.md         # Development workflow
â””â”€â”€ README.md                    # This file
```

## âš™ï¸ System Components

### **STT Server** (Port 8888)
- Real-time speech recognition with faster-whisper
- GPU-accelerated transcription
- Echo cancellation during TTS playback
- Custom whisper models for accuracy

### **TTS Server** (Port 5051)
- Natural voice synthesis with Piper
- GPU-accelerated with CUDA/ONNX Runtime
- Custom voice model (skeletor_v1)
- Coordinates with STT to prevent echo

### **LLM Preprocessor** (Port 5000)
- Ollama-based conversation AI
- Vector memory with PostgreSQL + pgvector
- GLiClass zero-shot classification
- Smart context retrieval
- Web chat interface

### **Service Control Panel** (Port 5555)
- Web-based management interface
- Start/stop all services
- Real-time log streaming
- Status monitoring

## ğŸ¯ Key Features

âœ… **Voice-to-Voice AI** - Speak naturally, hear responses  
âœ… **Persistent Memory** - Remembers conversations across sessions  
âœ… **Smart Retrieval** - GLiClass classification + vector similarity  
âœ… **GPU Accelerated** - Fast transcription and synthesis  
âœ… **Zero Echo** - Proper coordination prevents feedback loops  
âœ… **Easy Management** - One-click control panel  
âœ… **Production Ready** - Error handling, logging, monitoring  

## ğŸ”§ Technical Stack

- **Python 3.11** - Core language
- **CUDA 12.x** - GPU acceleration
- **faster-whisper** - STT engine
- **Piper TTS** - TTS engine
- **Ollama** - LLM backend (llama3.2:3b)
- **GLiClass** - Zero-shot classification
- **PostgreSQL + pgvector** - Vector memory
- **Flask + SocketIO** - Web framework
- **PyAudio + sounddevice** - Audio I/O

## ğŸ“Š Performance

- **Voice Response:** ~5-9 seconds end-to-end
- **STT Latency:** 2-4 seconds
- **LLM Generation:** 1-3 seconds  
- **TTS Synthesis:** <1 second
- **GPU Usage:** RTX 3060 or equivalent

## ğŸŒ Network Topology

All services run on **192.168.1.154** (this machine):
- Windows services: STT, TTS, Ollama, Control Panel
- WSL services: v34 LLM Preprocessor
- External: ESP32 display at 192.168.1.110:8080

Communication via localhost (STTâ†”TTS, v34â†”Ollama) and LAN (v34â†”TTS).

## ğŸ“ Common Tasks

### **Starting Everything**
```bash
# Launch control panel
testing-interface\START_CONTROL_PANEL.bat
# Then visit http://localhost:5555
```

### **Making Changes**
```bash
# Edit files in WSL location
cd ~/timmy-backend/little-timmy
# Make your changes
git add .
git commit -m "Your message"
git push origin main
```

### **Debugging**
- Control panel shows real-time logs
- Service logs in `testing-interface/logs/`
- Debug mode flags: `--debug` or `--ai`

## ğŸ› Known Issues

- âš ï¸ Log file permissions on WSL filesystem (handled gracefully)
- âš ï¸ Control panel cleanup requires signal handlers (fixed)
- âš ï¸ Old Windows copy at C:\Users\dsm27\little_timmy (TODO: delete)

## ğŸ“ Learning Resources

- **Piper TTS:** https://github.com/rhasspy/piper
- **faster-whisper:** https://github.com/guillaumekln/faster-whisper
- **GLiClass:** https://github.com/knowledgator/gliclass
- **Ollama:** https://ollama.ai/

## ğŸ¤ Contributing

This is a personal project, but follows standard Git workflow:
1. Make changes in WSL repository
2. Test with control panel
3. Commit and push to GitHub

## ğŸ“œ License

MIT License - See v34/LICENSE for details

## ğŸ† Project Status

**Status:** âœ… Production Ready  
**Last Updated:** November 27, 2025  
**Version:** v34 (LLM), v17 (STT), v2 (TTS)

---

**Repository:** https://github.com/dan-gearscodeandfire/little_timmy  
**Maintainer:** Dan (gearscodeandfire)
